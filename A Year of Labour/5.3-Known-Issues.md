# 5.3 â€” Known Issues

- Some citations are simply wrong. The entire set of sources was lost on initial import from markdown, and a combination of manual and AI-assisted re-integration was necessary. Some citations are not as relevant to the points they're supporting as an entirely human research team would prefer, but they should be good enough to point a reader in the right direction, if not directly to the exact correct link. 
    - Made good progress on this, still have some to re-link and check. 
- Quotes/takes based on sources are _generally_ correct, but qualifiers and quote accuracy could be much better. A full human follow-up could improve these links.
- This is as much an experiment in how AI/LLMs can be used to support the generation of detailed and data-heavy reports in complex fields, and how it can potentially turn subjective analysis into actionable data. Conclusions are not guaranteed to be completely objective, but only as close as we can reasonably expect within the scope of this experiment.
- This report is published as an open document, if you can add anything of value or there's anything you don't like, get involved on the github repo and help us improve it.
- All policies were reviewed by a human, but humans are not perfect (understatement of the century). We do not know everything, if you know better on any policy and want to revise its score, open a PR or Issue on the github with your reasoning.
- The primary researcher/author and reviewers are from a pretty narrow demographic window. Could do better in future with the support of more diverse collaborators with a broader range of experience and evaluation criteria.