# A) Basics & origin

The Online Safety Act is the UK trying to move safety work off your shoulders and onto the systems that shape what you see. Instead of more pop‑ups and finger‑wagging, it asks the big services to do the boring but important plumbing: know their risks, design safer defaults, and fix things when they break.

It wasn’t born overnight or by one party. The idea rolled through years of debate, election cycles and rewrites, and ended up as a cross‑party push with Ofcom holding the clipboard. Think of this section as the quick map: what the law actually is, who it touches, and where its edges are.

<details>
<summary><strong>What is the Online Safety Act (OSA)?</strong></summary>
A UK law that puts duties on online services (not on users) to reduce illegal harms and protect children. Separate parts of the law create or update offences for individuals (e.g., cyberflashing), but the core of the OSA is about what <em>services</em> must do.

In practice, the OSA sets out who is in scope, requires risk assessments and safety systems, and empowers Ofcom to enforce compliance. See the primary Act for the full structure and definitions: <em>Online Safety Act 2023</em> on legislation.gov.uk. ([legislation.gov.uk](https://www.legislation.gov.uk/ukpga/2023/50))

The rules can also apply to services <strong>outside the UK</strong> if their service has a <strong>“UK link.”</strong> Ofcom’s scope overview explains the UK link tests and exemptions with clear diagrams. ([Ofcom—Regulated services: overview of scope (PDF)](https://www.ofcom.org.uk/__data/assets/pdf_file/0018/273576/Regulated-services-overview-of-scope.PDF))
</details>

<details>
<summary><strong>Who created it and who pushed it over the line?</strong></summary>
The policy started as the UK’s <em>Online Harms</em> programme (2019), the Bill was introduced to Parliament in March 2022, the Act received Royal Assent on 26 October 2023, and the current government accelerated delivery from mid‑2024.

- <strong>Origins (2019)</strong>: The UK Government published the <em>Online Harms White Paper</em> in April 2019 under then‑Prime Minister Theresa May, proposing a duty of care and a regulator to oversee online safety. ([gov.uk—White Paper](https://www.gov.uk/government/consultations/online-harms-white-paper))
- <strong>Government response (Dec 2020)</strong>: The full response confirmed a statutory duty of care and Ofcom as regulator. ([gov.uk—Full government response](https://www.gov.uk/government/consultations/online-harms-white-paper/public-feedback/online-harms-white-paper-full-government-response))
- <strong>Draft Bill (May 2021)</strong>: A draft <em>Online Safety Bill</em> was published for pre‑legislative scrutiny by a Joint Committee. ([gov.uk—Draft Online Safety Bill](https://www.gov.uk/government/publications/draft-online-safety-bill))
- <strong>Introduction to Parliament (2022)</strong>: Culture Secretary Nadine Dorries introduced the <em>Online Safety Bill</em> to the Commons in March 2022. ([gov.uk—Press/Parliamentary materials](https://www.gov.uk/government/collections/online-safety-bill))
- <strong>Royal Assent (2023)</strong>: The Bill became the <em>Online Safety Act 2023</em> on 26 October 2023. ([legislation.gov.uk](https://www.legislation.gov.uk/ukpga/2023/50/contents))
- <strong>Acceleration (2024→)</strong>: From July 2024, the government prioritised fast implementation via Ofcom’s phased codes and guidance rather than reopening the statute. Ofcom is the regulator responsible for writing codes, auditing, and enforcement. ([Ofcom—Roadmap to regulation](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/roadmap-to-regulation))
</details>

<details>
<summary><strong>Why did Labour keep/accelerate it after 2024?</strong></summary>
It was already law, public support for child protection is high, Ofcom’s roadmap was running, and ministers can shape delivery through strategic priorities and secondary measures rather than re‑legislate.

The government’s own explainer emphasises platform duties and phased commencement, which made delivery the pragmatic path. In May 2025 ministers also issued strategic priorities to guide Ofcom’s approach. See: the official <em>Online Safety Act explainer</em> ([gov.uk](https://www.gov.uk/government/publications/online-safety-act-explainer/online-safety-act-explainer)) and Ofcom’s online safety hub/roadmap ([Ofcom](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/roadmap-to-regulation)).
</details>

<details>
<summary><strong>What services are in scope?</strong></summary>
<strong>User‑to‑user services</strong> and <strong>search services</strong> with a UK link. Duties scale with size, functionality and risk.

- <strong>User‑to‑user services</strong>: services where content a user generates, uploads or shares can be <em>encountered by other users</em>. This can include public posts and features like group chats/DMs where content is shared beyond a single user. See the definition in Part 2, <strong>s.3</strong>. ([legislation—s.3](https://www.legislation.gov.uk/ukpga/2023/50/section/3))
- <strong>Search services</strong>: services that search multiple websites/databases and present results. Part 2, <strong>s.4</strong>. ([legislation—s.4](https://www.legislation.gov.uk/ukpga/2023/50/section/4))
- <strong>UK link</strong>: a service is in scope if any of the following apply: it has a <strong>significant number of UK users</strong>; it <strong>targets the UK</strong>; or it is <strong>accessible in the UK</strong> and there is a <strong>material risk of significant harm</strong> to UK users. Part 2, <strong>s.5</strong>; see Ofcom’s plain‑English overview for examples. ([legislation—s.5](https://www.legislation.gov.uk/ukpga/2023/50/section/5), [Ofcom—Regulated services overview (PDF)](https://www.ofcom.org.uk/__data/assets/pdf_file/0018/273576/Regulated-services-overview-of-scope.PDF))

Note: <strong>one‑to‑one live voice calls</strong> are exempt, but <strong>video calls and messaging content</strong> are not. Group chats and DMs can be in scope where content one user sends can be encountered by another. (See Ofcom’s overview linked above.)

For a plain‑English overview, see the government explainer (which also notes private messaging can be in scope where content is shared): ([gov.uk—OSA explainer](https://www.gov.uk/government/publications/online-safety-act-explainer/online-safety-act-explainer)).
</details>

<details>
<summary><strong>What is <em>out</em> of scope?</strong></summary>
Certain <strong>service types</strong> and <strong>limited‑functionality features</strong> are exempt. Examples:

- Standard <strong>email and SMS/MMS</strong>.
- <strong>One‑to‑one live aural (voice) calls</strong> (including VoIP voice calls).
- <strong>Internal business/enterprise tools</strong> (closed workforce services).
- <strong>Limited‑functionality exemptions</strong> (e.g., services without user‑to‑user features).
- <strong>Recognised news publisher content</strong> itself is outside scope; <em>user comments around it</em> can be in scope.

Details live in <strong>Schedule 1</strong> and <strong>Schedule 2</strong> of the Act; Ofcom’s scope overview summarises what’s in/out and explains transitional rules. ([legislation—Schedule 1](https://www.legislation.gov.uk/ukpga/2023/50/schedule/1), [legislation—Schedule 2](https://www.legislation.gov.uk/ukpga/2023/50/schedule/2), [Ofcom—Regulated services overview (PDF)](https://www.ofcom.org.uk/__data/assets/pdf_file/0018/273576/Regulated-services-overview-of-scope.PDF))
</details>

<details>
<summary><strong>What the OSA <em>doesn’t</em> do</strong></summary>
- It doesn’t impose a general “ID for everyone.” The law is risk‑based and method‑agnostic; self‑declaration doesn’t count, but several privacy‑preserving methods do. ([Ofcom—Protecting children online (codes)](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/statement-protecting-children-from-harms-online))
- It doesn’t ban end‑to‑end encryption (E2EE). Ofcom could, in theory, issue <strong>Technology Notices</strong> requiring <strong>accredited</strong> detection technology <strong>only where technically feasible</strong>; both government and Ofcom have framed this as a high bar and consulted on minimum accuracy standards. ([gov.uk—OSA explainer](https://www.gov.uk/government/publications/online-safety-act-explainer/online-safety-act-explainer), [Ofcom—Illegal harms statement hub](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/statement-protecting-people-from-illegal-harms-online))
- It doesn’t create blanket bans on legal speech for adults. Instead, services must apply their own terms consistently and offer tools/appeals. ([gov.uk—OSA explainer](https://www.gov.uk/government/publications/online-safety-act-explainer/online-safety-act-explainer))
</details>

<details>
<summary><strong>What the OSA <em>does</em> require from services</strong></summary>
- <strong>Assess risks</strong> (illegal content; and for kids, content likely to harm) and keep assessments up to date. (Part 3 duties; Ofcom guidance and templates in its online safety hub.) ([Ofcom—hub](https://www.ofcom.org.uk/online-safety))
- <strong>Design and operate systems</strong> that reduce those risks (moderation, reporting, user controls, safer defaults for children). ([Ofcom—codes](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/statement-protecting-children-from-harms-online))
- <strong>Use “highly effective” age assurance</strong> where needed (several methods are acceptable; self‑declaration is not). ([Ofcom—codes](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/statement-protecting-children-from-harms-online))
- <strong>Be transparent</strong> (clear terms, complaints/appeals) and cooperate with Ofcom audits and information requests. (Part 7 powers; see Ofcom roadmap.) ([Ofcom—roadmap](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/roadmap-to-regulation))
- <strong>Face penalties</strong> if they won’t fix issues: Ofcom can fine up to <strong>£18m or 10% of qualifying worldwide revenue</strong> (whichever is greater) and, in severe cases, seek <strong>court‑ordered business disruption</strong> measures (e.g., payment/ads withdrawal or ISP access restrictions). ([Ofcom—Enforcement guidance (PDF)](https://www.ofcom.org.uk/siteassets/resources/documents/online-safety/information-for-industry/illegal-harms/online-safety-enforcement-guidance.pdf?v=391925), [gov.uk—OSA explainer](https://www.gov.uk/government/publications/online-safety-act-explainer/online-safety-act-explainer))
</details>

<details>
<summary><strong>Key dates (high level)</strong></summary>
- <strong>17 March 2025</strong>: Illegal‑content duties enforceable; risk assessments due. ([gov.uk—OSA explainer](https://www.gov.uk/government/publications/online-safety-act-explainer/online-safety-act-explainer), [Ofcom—roadmap](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/roadmap-to-regulation))
- <strong>25 July 2025</strong>: Child‑safety codes and age‑assurance expectations in force for services likely to be accessed by children (after a 3‑month risk‑assessment window to <strong>24 July 2025</strong>). ([Ofcom—Protecting children online](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/protecting-children-online))
- <strong>Through 2026</strong>: Further codes (e.g., for categorised services) and transparency reporting phases roll out. ([Ofcom—roadmap](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/roadmap-to-regulation))
</details>

<details>
<summary><strong>Categorised services (extra duties)</strong></summary>
Some services face <strong>additional transparency and user‑empowerment duties</strong> based on thresholds set by secondary legislation in 2025. Broadly:

- <strong>Category 1</strong>: very large user‑to‑user services (size + functionality thresholds).
- <strong>Category 2A</strong>: large <em>search</em> services.
- <strong>Category 2B</strong>: sizable user‑to‑user services below Cat 1 but with risky features (e.g., DMs).

Thresholds were set by the <em>Online Safety Act 2023 (Category 1, Category 2A and Category 2B Threshold Conditions) Regulations 2025</em>. ([UK SI 2025/226—Threshold Conditions (PDF)](https://upload.wikimedia.org/wikipedia/commons/7/77/The_Online_Safety_Act_2023_%28Category_1%2C_Category_2A_and_Category_2B_Threshold_Conditions%29_Regulations_2025_%28UKSI_2025-226_kp%29.pdf))
</details>


<details>
<summary><strong>Online Safety Act at a glance</strong></summary>
- Sets <em>system-level duties</em> for services with a UK link; it is not a tool for policing individual posts.
- Core focus: <strong>illegal content</strong> and <strong>children’s safety</strong>; adults get more control tools, not new bans on legal speech.
- Enforced by <strong>Ofcom</strong>, with fines up to <strong>£18m or 10% of qualifying worldwide revenue</strong> and, in serious cases, <strong>court-ordered business disruption</strong> measures. 

See Ofcom’s enforcement approach and the government explainer: [Ofcom—Enforcement guidance (PDF)](https://www.ofcom.org.uk/siteassets/resources/documents/online-safety/information-for-industry/illegal-harms/online-safety-enforcement-guidance.pdf?v=391925) or the [gov.uk OSA explainer](https://www.gov.uk/government/publications/online-safety-act-explainer/online-safety-act-explainer).
</details>

