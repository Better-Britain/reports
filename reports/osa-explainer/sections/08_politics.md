# H) Politics & perception

<details>
<summary><strong>Why did age verification become the story?</strong></summary>
It’s visible and deadline‑driven: ordinary adults meet it at point‑of‑use. The harder work (risk assessments, safer defaults, audits) happens out of sight. Media and creators naturally amplify what people can feel right now (see Ofcom’s phased [roadmap](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/roadmap-to-regulation)).

Coverage through mid‑2025 and beyond focused on Reddit’s selfie‑based rollout and Steam’s credit‑card approach, which sparked strong reactions across gaming and creator spaces. See, for instance, the BBC on Reddit’s UK rollout ([BBC News](https://www.bbc.com/news/articles/cj4ep1znk4zo)) and developer press on Steam’s card‑on‑file design ([Game Developer](https://www.gamedeveloper.com/business/you-now-need-a-credit-card-to-access-mature-content-on-steam-in-the-uk)).
</details>

<details>
<summary><strong>Manufactured disconsent: why gamer spaces ignite</strong></summary>
Frustration with clumsy implementations is real. Some actors redirect that into rejecting governance itself (“all rules are tyranny”). Gaming communities have long had the tools for fast mobilisation (raids, brigades, review‑bombs). That makes them fertile ground for turning “bad design choice” into “law is illegitimate.” Our sourced notes trace this pattern through earlier cycles (e.g., Gamergate coordination) and show how platform choices can fuel it.

Polling in 2025 suggests broad support for protecting kids alongside scepticism about effectiveness. For example, a July 2025 YouGov poll reported high support for age verification but doubts about outcomes, and an August 2025 Ipsos study found many Britons back checks while questioning how well they work. Linking to such polls helps explain why public sentiment can be pro‑safety yet critical of clunky designs. ([YouGov poll results](https://yougov.co.uk/topics/society/survey-results/daily/2025/07/24/8b234/3), [Ipsos—Adults and age checks](https://www.ipsos.com/en-uk/britons-back-online-safety-acts-age-checks-are-sceptical-effectiveness-and-unwilling-share-id)).
</details>

<details>
<summary><strong>What should platforms do to avoid backlash?</strong></summary>
Design for privacy first (deletion, non‑ID options), give a choice of methods, explain plainly, and provide fast appeals. Don’t shift the burden onto users. People will still grumble, but the temperature drops when the friction feels respectful and optional (mirroring Ofcom’s outcomes‑not‑one‑tool approach in the [children’s codes](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/statement-protecting-children-from-harms-online)).
</details>

<details>
<summary><strong>Follow‑up: why do some companies over‑comply?</strong></summary>
Incentives: legal uncertainty, fear of large fines, and tight timelines push legal teams toward blunt, audit‑friendly choices. A single gate (e.g., “card on file”) is easier to evidence than nuanced, targeted design. But it’s also more exclusionary and angers users—ironically fuelling the backlash. Ofcom’s approach leaves room for layered, privacy‑preserving methods; companies should use that room.
</details>

